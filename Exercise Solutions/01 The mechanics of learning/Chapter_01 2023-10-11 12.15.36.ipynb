{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfGX985EjyJt",
    "outputId": "7ca10b6f-6cfe-48e8-8acb-b7fd7e6339ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: libsvmdata in /usr/local/lib/python3.8/dist-packages (0.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from libsvmdata) (1.0.2)\n",
      "Requirement already satisfied: download in /usr/local/lib/python3.8/dist-packages (from libsvmdata) (0.3.5)\n",
      "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from libsvmdata) (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from libsvmdata) (1.7.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from download->libsvmdata) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from download->libsvmdata) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from download->libsvmdata) (4.64.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->download->libsvmdata) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->download->libsvmdata) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->download->libsvmdata) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->download->libsvmdata) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->libsvmdata) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->libsvmdata) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "import timeit\n",
    "\n",
    "!pip install libsvmdata\n",
    "\n",
    "from libsvmdata import fetch_libsvm\n",
    "\n",
    "torch_tensor3d = torch.tensor([ \n",
    "                             [ \n",
    "                             [ 1, 2, 3], \n",
    "                             [ 4, 5, 6], \n",
    "                             ], \n",
    "                             [ \n",
    "                             [ 7, 8, 9], \n",
    "                             [10, 11, 12], \n",
    "                             ], \n",
    "                             [ \n",
    "                             [13, 14, 15], \n",
    "                             [16, 17, 18], \n",
    "                             ], \n",
    "                             [\n",
    "                             [19, 20, 21],\n",
    "                             [22, 23, 24],\n",
    "                             ] \n",
    "                            ])\n",
    "\n",
    "def moveTo(obj, device): \n",
    "    \"\"\" \n",
    "    obj: the python object to move to a device, or to move its\n",
    "    ➥ contents to a device\n",
    "    device: the compute device to move objects to \n",
    "    \"\"\"\n",
    "    if isinstance(obj, list): \n",
    "        return [moveTo(x, device) for x in obj] \n",
    "    elif isinstance(obj, tuple): \n",
    "        return tuple(moveTo(list(obj), device)) \n",
    "    elif isinstance(obj, set): \n",
    "        return set(moveTo(list(obj), device)) \n",
    "    elif isinstance(obj, dict): \n",
    "        to_ret = dict() \n",
    "        for key, value in obj.items(): \n",
    "            to_ret[moveTo(key, device)] = moveTo(value, device) \n",
    "        return to_ret \n",
    "    elif hasattr(obj, \"to\"): \n",
    "        return obj.to(device) \n",
    "    else: \n",
    "        return obj\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y): \n",
    "        super(SimpleDataset, self).__init__()\n",
    "        self.X = X \n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        inputs = torch.tensor(self.X.iloc[index, :], dtype=torch.float32)\n",
    "        targets = torch.tensor(int(self.y[index]), dtype=torch.int64) \n",
    "        return inputs, targets\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.X.shape[0]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWAAHXTWkFmC",
    "outputId": "87d68378-dd6e-4c67-b93d-cf3d891c09b4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch_tensor3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d2):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d3):\n\u001b[1;32m----> 9\u001b[0m       \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mtorch_tensor3d\u001b[49m[i,j,k]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m \u001b[38;5;241m/\u001b[39m (d1 \u001b[38;5;241m*\u001b[39m d2 \u001b[38;5;241m*\u001b[39m d3))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch_tensor3d' is not defined"
     ]
    }
   ],
   "source": [
    "# Write a series of for loops that compute the average value in torch_tensor3d.\n",
    "d1 = 4\n",
    "d2 = 2\n",
    "d3 = 3\n",
    "sum = 0\n",
    "for i in range(d1):\n",
    "  for j in range(d2):\n",
    "    for k in range(d3):\n",
    "      sum = sum + torch_tensor3d[i,j,k]\n",
    "print(sum / (d1 * d2 * d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KC6utjvMkOTy",
    "outputId": "d836a995-4128-4d01-e9e3-60bb4af4040a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13)\n"
     ]
    }
   ],
   "source": [
    "# Write code that indexes into torch_tensor3d and prints out the value 13. \n",
    "print(torch_tensor3d[2, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "J0GCAg5_kYGS",
    "outputId": "b19d7245-6e5a-4293-c1da-e2bf28e1a2b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9b1bd40100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For every power of 2 (i.e., 2i or 2**i ) up to 211, create a random matrix X ∈ ℝ2i, 2i (i.e., X.shape should give (2**i, 2**i)).\n",
    "# Time how long it takes to compute XX (i.e., X @ X) on a CPU and on a GPU, and plot the speedup.\n",
    "# For what matrix sizes is the CPU faster than the GPU? \n",
    "\n",
    "result_cpu = np.empty((12, 2))\n",
    "for i in range(12):\n",
    "  X = np.random.random((2**i,2**i)) \n",
    "  time_cpu = timeit.timeit(\"X@X\", globals=globals(), number=100)\n",
    "  result_cpu[i, 0] = i\n",
    "  result_cpu[i, 1] = time_cpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print(\"GPU acceleration is available\")\n",
    "  device = torch.device(\"cuda\") \n",
    "  result_gpu = np.empty((12, 2))\n",
    "  for i in range(12):\n",
    "    X = np.random.random((2**i,2**i)) \n",
    "    X = moveTo(X, device) \n",
    "    time_gpu = timeit.timeit(\"X@X\", globals=globals(), number=100)\n",
    "    result_gpu[i, 0] = i\n",
    "    result_gpu[i, 1] = time_gpu\n",
    "    if result_cpu[i, 1] > result_gpu[i, 1]:\n",
    "      print(f\"2^{i}: GPU wins\")\n",
    "    else:\n",
    "      print(f\"2^{i}: CPU wins\")   \n",
    "  sns.lineplot(x=result_gpu[:,0], y=result_gpu[:,1], label='gpu')  \n",
    "\n",
    "sns.lineplot(x=result_cpu[:,0], y=result_cpu[:,1], label='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXlrWJ4Pkjcd",
    "outputId": "c3f37a88-0074-44fa-aa61-9bb2cdcf692c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1.0635]) f(x): tensor([-6.8625])\n"
     ]
    }
   ],
   "source": [
    "# We used PyTorch to find the numeric solution to f(x) = (x−2)2.\n",
    "# Write code that finds the solution to f(x) = sin(x − 2) · (x + 2)2 + √|cos(x)|.\n",
    "# What answer doyou get? \n",
    "\n",
    "def f(x):\n",
    "  return torch.multiply(torch.sin((x-2.0)), torch.pow(x + 2.0, 2)) + torch.sqrt(torch.abs(torch.cos(x)))\n",
    "\n",
    "x_param = torch.nn.Parameter(torch.tensor([-3.0]), requires_grad=True)\n",
    "optimizer = torch.optim.SGD([x_param], lr=0.1)\n",
    "\n",
    "for epoch in range(100): \n",
    "    optimizer.zero_grad()\n",
    "    loss_incurred = f(x_param) \n",
    "    loss_incurred.backward() \n",
    "    optimizer.step()\n",
    "print(\"x:\", x_param.data, \"f(x):\", f(x_param.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNmdjUqIknFs",
    "outputId": "504bd325-aacc-4b90-d8dd-ee7113817281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([3.1419]) y: tensor([4.1419]) f(x, y): tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# Write a new function that takes two inputs, x and y, where f(x, y) = exp (sin(x)2)/(x−y)2 + (x−y)2 \n",
    "# Use an Optimizer with initial parameter values of x = 0.2 and y = 10.\n",
    "# What do they converge to? \n",
    "\n",
    "def f(x, y):\n",
    "  return torch.divide(torch.exp(torch.pow(torch.sin(x), 2.0)),\\\n",
    "                      torch.pow((x - y), 2.0)) +\\\n",
    "                      torch.pow((x - y), 2.0)\n",
    "x_param = torch.nn.Parameter(torch.tensor([0.2]), requires_grad=True)                      \n",
    "y_param = torch.nn.Parameter(torch.tensor([10.0]), requires_grad=True)    \n",
    "\n",
    "optimizer = torch.optim.SGD([x_param, y_param], lr=0.1)\n",
    "\n",
    "for epoch in range(100): \n",
    "    optimizer.zero_grad()\n",
    "    loss_incurred = f(x_param, y_param) \n",
    "    loss_incurred.backward() \n",
    "    optimizer.step()\n",
    "print(\"x:\", x_param.data, \"y:\", y_param.data,\"f(x, y):\", f(x_param.data, y_param.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaJ_GzL2ksxR",
    "outputId": "1d5ee616-f12a-4988-f40c-31174bef77f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7395, 1836)\n",
      "(7395, 159)\n"
     ]
    }
   ],
   "source": [
    "# Create a function libsvm2Dataset that takes a path to a libsvm dataset file \n",
    "# (see https://www.csie.ntu.edu.tw/ cjlin/libsvmtools/datasets/ for many that you can download)\n",
    "# and create a new dataset object.\n",
    "# Check that it is the correct length and that each row has the expected number of features. \n",
    "\n",
    "def libsvm2Dataset(datasetName):\n",
    "  X, y = fetch_libsvm(datasetName)\n",
    "  return SimpleDataset(X, y)\n",
    "\n",
    "dataset = libsvm2Dataset('bibtex')\n",
    "print (dataset.X.shape)\n",
    "print (dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKs8CRmQkwlB",
    "outputId": "b6d14cc6-29e6-43a6-bd76-09320683eb12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "Features:  torch.Size([784])\n",
      "Label of index 0:  tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Challenging: Use NumPy’s memmap functionality to write the MNIST dataset to disk.\n",
    "# Then create a MemmapedSimpleDataset that takes the mem-mapped file as input,\n",
    "# reading the matrix from disk to create PyTorch tensors in the __getitem__ method. Why do you think this would be useful? \n",
    "\n",
    "# Load minst data first\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Save data and shape into new file\n",
    "targetFile = np.memmap('array.npy', dtype='float32', mode='w+', shape=(X.shape[0] + 1, X.shape[1] + 1))\n",
    "targetFile[0, :2] = X.shape\n",
    "targetFile[1:, :-1] = X[:]\n",
    "targetFile[1:, -1] = y[:]\n",
    "\n",
    "\n",
    "# Solution itself\n",
    "class MemmapedSimpleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, fileName): \n",
    "      super(MemmapedSimpleDataset, self).__init__()\n",
    "      self.fileName = fileName\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "      openFile = np.memmap(self.fileName, dtype='float32', mode='r')\n",
    "      xshape = np.int_(openFile[:2])\n",
    "      openFile._mmap.close()\n",
    "      xshape[1]+=1\n",
    "      sourceFile = np.memmap(self.fileName, dtype='float32', mode='r', shape=tuple(xshape))\n",
    "      inputs = torch.tensor(sourceFile[index + 1, :-1], dtype=torch.float32)\n",
    "      targets = torch.tensor(int(sourceFile[index + 1, -1]), dtype=torch.int64) \n",
    "      return inputs, targets\n",
    "\n",
    "    def __len__(self): \n",
    "      openFile = np.memmap(self.fileName, dtype='float32', mode='r')\n",
    "      xshape = np.int_(openFile[:2])\n",
    "      openFile._mmap.close()\n",
    "      return xshape[0] \n",
    "\n",
    "mmds = MemmapedSimpleDataset('array.npy')\n",
    "print(len(mmds))\n",
    "example, label = mmds[0]\n",
    "print(\"Features: \", example.shape)\n",
    "print(\"Label of index 0: \", label) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
