{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfGX985EjyJt",
    "outputId": "7ca10b6f-6cfe-48e8-8acb-b7fd7e6339ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: libsvmdata in d:\\program files\\python39\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: download in d:\\program files\\python39\\lib\\site-packages (from libsvmdata) (0.3.5)\n",
      "Requirement already satisfied: numpy>=1.12 in d:\\program files\\python39\\lib\\site-packages (from libsvmdata) (1.23.4)\n",
      "Requirement already satisfied: scipy in d:\\program files\\python39\\lib\\site-packages (from libsvmdata) (1.9.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\program files\\python39\\lib\\site-packages (from libsvmdata) (1.1.3)\n",
      "Requirement already satisfied: tqdm in d:\\program files\\python39\\lib\\site-packages (from download->libsvmdata) (4.64.1)\n",
      "Requirement already satisfied: requests in d:\\program files\\python39\\lib\\site-packages (from download->libsvmdata) (2.28.1)\n",
      "Requirement already satisfied: six in d:\\program files\\python39\\lib\\site-packages (from download->libsvmdata) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\program files\\python39\\lib\\site-packages (from scikit-learn->libsvmdata) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\program files\\python39\\lib\\site-packages (from scikit-learn->libsvmdata) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\python39\\lib\\site-packages (from requests->download->libsvmdata) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\program files\\python39\\lib\\site-packages (from requests->download->libsvmdata) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\program files\\python39\\lib\\site-packages (from requests->download->libsvmdata) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\python39\\lib\\site-packages (from requests->download->libsvmdata) (3.4)\n",
      "Requirement already satisfied: colorama in d:\\program files\\python39\\lib\\site-packages (from tqdm->download->libsvmdata) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install libsvmdata\n",
    "\n",
    "# from libsvmdata import fetch_libsvm\n",
    "\n",
    "torch_tensor3d = torch.tensor([ \n",
    "                             [ \n",
    "                             [ 1, 2, 3], \n",
    "                             [ 4, 5, 6], \n",
    "                             ], \n",
    "                             [ \n",
    "                             [ 7, 8, 9], \n",
    "                             [10, 11, 12], \n",
    "                             ], \n",
    "                             [ \n",
    "                             [13, 14, 15], \n",
    "                             [16, 17, 18], \n",
    "                             ], \n",
    "                             [\n",
    "                             [19, 20, 21],\n",
    "                             [22, 23, 24],\n",
    "                             ] \n",
    "                            ])\n",
    "\n",
    "def moveTo(obj, device): \n",
    "    \"\"\" \n",
    "    obj: the python object to move to a device, or to move its\n",
    "    ➥ contents to a device\n",
    "    device: the compute device to move objects to \n",
    "    \"\"\"\n",
    "    if isinstance(obj, list): \n",
    "        return [moveTo(x, device) for x in obj] \n",
    "    elif isinstance(obj, tuple): \n",
    "        return tuple(moveTo(list(obj), device)) \n",
    "    elif isinstance(obj, set): \n",
    "        return set(moveTo(list(obj), device)) \n",
    "    elif isinstance(obj, dict): \n",
    "        to_ret = dict() \n",
    "        for key, value in obj.items(): \n",
    "            to_ret[moveTo(key, device)] = moveTo(value, device) \n",
    "        return to_ret \n",
    "    elif hasattr(obj, \"to\"): \n",
    "        return obj.to(device) \n",
    "    else: \n",
    "        return obj\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y): \n",
    "        super(SimpleDataset, self).__init__()\n",
    "        self.X = X \n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        inputs = torch.tensor(self.X.iloc[index, :], dtype=torch.float32)\n",
    "        targets = torch.tensor(int(self.y[index]), dtype=torch.int64) \n",
    "        return inputs, targets\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.X.shape[0]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWAAHXTWkFmC",
    "outputId": "87d68378-dd6e-4c67-b93d-cf3d891c09b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.5000)\n"
     ]
    }
   ],
   "source": [
    "# Write a series of for loops that compute the average value in torch_tensor3d.\n",
    "d1 = 4\n",
    "d2 = 2\n",
    "d3 = 3\n",
    "sum = 0\n",
    "for i in range(d1):\n",
    "  for j in range(d2):\n",
    "    for k in range(d3):\n",
    "      sum = sum + torch_tensor3d[i,j,k]\n",
    "print(sum / (d1 * d2 * d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KC6utjvMkOTy",
    "outputId": "d836a995-4128-4d01-e9e3-60bb4af4040a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13)\n"
     ]
    }
   ],
   "source": [
    "# Write code that indexes into torch_tensor3d and prints out the value 13. \n",
    "print(torch_tensor3d[2, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "J0GCAg5_kYGS",
    "outputId": "b19d7245-6e5a-4293-c1da-e2bf28e1a2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU acceleration is available\n",
      "2^0: GPU wins\n",
      "2^1: GPU wins\n",
      "2^2: GPU wins\n",
      "2^3: GPU wins\n",
      "2^4: GPU wins\n",
      "2^5: GPU wins\n",
      "2^6: CPU wins\n",
      "2^7: GPU wins\n",
      "2^8: GPU wins\n",
      "2^9: GPU wins\n",
      "2^10: GPU wins\n",
      "2^11: CPU wins\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for axis 0 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m X \u001b[38;5;241m=\u001b[39m moveTo(X, device) \n\u001b[0;32m     19\u001b[0m time_gpu \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mtimeit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX@X\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m(), number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mresult_gpu\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m     21\u001b[0m result_gpu[i, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m time_gpu\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_cpu[i, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m result_gpu[i, \u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 12 is out of bounds for axis 0 with size 12"
     ]
    }
   ],
   "source": [
    "# For every power of 2 (i.e., 2i or 2**i ) up to 211, create a random matrix X ∈ ℝ2i, 2i (i.e., X.shape should give (2**i, 2**i)).\n",
    "# Time how long it takes to compute XX (i.e., X @ X) on a CPU and on a GPU, and plot the speedup.\n",
    "# For what matrix sizes is the CPU faster than the GPU? \n",
    "\n",
    "result_cpu = np.empty((12, 2))\n",
    "for i in range(12):\n",
    "    X = np.random.random((2**i,2**i)) \n",
    "    time_cpu = timeit.timeit(\"X@X\", globals=globals(), number=100)\n",
    "    result_cpu[i, 0] = i\n",
    "    result_cpu[i, 1] = time_cpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU acceleration is available\")\n",
    "    device = torch.device(\"cuda\") \n",
    "    result_gpu = np.empty((12, 2))\n",
    "    for i in range(12):\n",
    "    X = np.random.random((2**i,2**i)) \n",
    "    X = moveTo(X, device) \n",
    "    time_gpu = timeit.timeit(\"X@X\", globals=globals(), number=100)\n",
    "    result_gpu[i, 0] = i\n",
    "    result_gpu[i, 1] = time_gpu\n",
    "    if result_cpu[i, 1] > result_gpu[i, 1]:\n",
    "    print(f\"2^{i}: GPU wins\")\n",
    "    else:\n",
    "    print(f\"2^{i}: CPU wins\")   \n",
    "    sns.lineplot(x=result_gpu[:,0], y=result_gpu[:,1], label='gpu')  \n",
    "\n",
    "sns.lineplot(x=result_cpu[:,0], y=result_cpu[:,1], label='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXlrWJ4Pkjcd",
    "outputId": "c3f37a88-0074-44fa-aa61-9bb2cdcf692c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([3.1416]) y tensor([4.1416]) f(x, y): tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# We used PyTorch to find the numeric solution to f(x) = (x−2)2.\n",
    "# Write code that finds the solution to f(x) = sin(x − 2) · (x + 2)2 + √|cos(x)|.\n",
    "# What answer doyou get? \n",
    "\n",
    "def f1(x):\n",
    "    return torch.sin(x-2.0) + torch.pow(x + 2.0, 2) + torch.sqrt(torch.abs(torch.cos(x)))\n",
    "\n",
    "def f2(x, y):\n",
    "    return torch.exp(torch.pow(torch.sin(x), 2)) / torch.pow(x-y,2) + torch.pow(x-y,2)\n",
    "\n",
    "x_param = torch.nn.Parameter(torch.tensor([0.2]), requires_grad=True)\n",
    "y_param = torch.nn.Parameter(torch.tensor([10.0]), requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([x_param, y_param], lr=0.1)\n",
    "\n",
    "loss_list = []\n",
    "for epoch in range(1000): \n",
    "    optimizer.zero_grad()\n",
    "    loss_incurred = f2(x_param, y_param) \n",
    "    loss_list.append(loss_incurred.item())\n",
    "    loss_incurred.backward() \n",
    "    optimizer.step()\n",
    "print(\"x:\", x_param.data, \"y\", y_param.data, \"f(x, y):\", f2(x_param.data, y_param.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(len(loss_list)))\n",
    "plt.plot(x,loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNmdjUqIknFs",
    "outputId": "504bd325-aacc-4b90-d8dd-ee7113817281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([3.1419]) y: tensor([4.1419]) f(x, y): tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# Write a new function that takes two inputs, x and y, where f(x, y) = exp (sin(x)2)/(x−y)2 + (x−y)2 \n",
    "# Use an Optimizer with initial parameter values of x = 0.2 and y = 10.\n",
    "# What do they converge to? \n",
    "\n",
    "def f(x, y):\n",
    "  return torch.divide(torch.exp(torch.pow(torch.sin(x), 2.0)),\\\n",
    "                      torch.pow((x - y), 2.0)) +\\\n",
    "                      torch.pow((x - y), 2.0)\n",
    "x_param = torch.nn.Parameter(torch.tensor([0.2]), requires_grad=True)                      \n",
    "y_param = torch.nn.Parameter(torch.tensor([10.0]), requires_grad=True)    \n",
    "\n",
    "optimizer = torch.optim.SGD([x_param, y_param], lr=0.1)\n",
    "\n",
    "for epoch in range(100): \n",
    "    optimizer.zero_grad()\n",
    "    loss_incurred = f(x_param, y_param) \n",
    "    loss_incurred.backward() \n",
    "    optimizer.step()\n",
    "print(\"x:\", x_param.data, \"y:\", y_param.data,\"f(x, y):\", f(x_param.data, y_param.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaJ_GzL2ksxR",
    "outputId": "1d5ee616-f12a-4988-f40c-31174bef77f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7395, 1836)\n",
      "(7395, 159)\n"
     ]
    }
   ],
   "source": [
    "# Create a function libsvm2Dataset that takes a path to a libsvm dataset file \n",
    "# (see https://www.csie.ntu.edu.tw/ cjlin/libsvmtools/datasets/ for many that you can download)\n",
    "# and create a new dataset object.\n",
    "# Check that it is the correct length and that each row has the expected number of features. \n",
    "\n",
    "def libsvm2Dataset(datasetName):\n",
    "  X, y = fetch_libsvm(datasetName)\n",
    "  return SimpleDataset(X, y)\n",
    "\n",
    "dataset = libsvm2Dataset('bibtex')\n",
    "print (dataset.X.shape)\n",
    "print (dataset.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKs8CRmQkwlB",
    "outputId": "b6d14cc6-29e6-43a6-bd76-09320683eb12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "Features:  torch.Size([784])\n",
      "Label of index 0:  tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Challenging: Use NumPy’s memmap functionality to write the MNIST dataset to disk.\n",
    "# Then create a MemmapedSimpleDataset that takes the mem-mapped file as input,\n",
    "# reading the matrix from disk to create PyTorch tensors in the __getitem__ method. Why do you think this would be useful? \n",
    "\n",
    "# Load minst data first\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Save data and shape into new file\n",
    "targetFile = np.memmap('array.npy', dtype='float32', mode='w+', shape=(X.shape[0] + 1, X.shape[1] + 1))\n",
    "targetFile[0, :2] = X.shape\n",
    "targetFile[1:, :-1] = X[:]\n",
    "targetFile[1:, -1] = y[:]\n",
    "\n",
    "\n",
    "# Solution itself\n",
    "class MemmapedSimpleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, fileName): \n",
    "      super(MemmapedSimpleDataset, self).__init__()\n",
    "      self.fileName = fileName\n",
    "\n",
    "    def __getitem__(self, index): \n",
    "      openFile = np.memmap(self.fileName, dtype='float32', mode='r')\n",
    "      xshape = np.int_(openFile[:2])\n",
    "      openFile._mmap.close()\n",
    "      xshape[1]+=1\n",
    "      sourceFile = np.memmap(self.fileName, dtype='float32', mode='r', shape=tuple(xshape))\n",
    "      inputs = torch.tensor(sourceFile[index + 1, :-1], dtype=torch.float32)\n",
    "      targets = torch.tensor(int(sourceFile[index + 1, -1]), dtype=torch.int64) \n",
    "      return inputs, targets\n",
    "\n",
    "    def __len__(self): \n",
    "      openFile = np.memmap(self.fileName, dtype='float32', mode='r')\n",
    "      xshape = np.int_(openFile[:2])\n",
    "      openFile._mmap.close()\n",
    "      return xshape[0] \n",
    "\n",
    "mmds = MemmapedSimpleDataset('array.npy')\n",
    "print(len(mmds))\n",
    "example, label = mmds[0]\n",
    "print(\"Features: \", example.shape)\n",
    "print(\"Label of index 0: \", label) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dlpytorch",
   "language": "python",
   "name": "dlpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
